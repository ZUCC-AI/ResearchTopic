# LM：预训练语言模型 Pre-trained Language Model研究

主要研究的对象是当下深度学习非常火热的预训练语言模型(BERT、RoBERTa..)

是16级张凯学长和18级楼仁泽学长和美国藤校Dartmouth一起合作研究的课题

## 研究成果：

- ACL2021一篇（张凯学长共同一作，楼仁泽学长三作）
- EMNLP2021一篇（楼仁泽学长共同一作，张凯学长三作）

